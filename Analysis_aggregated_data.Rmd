---
title: "Analysis of aggregated data"
author: "Dominik Klepl"
date: "23 5 2018"
output: html_document
---
```{r library}
pacman::p_load(rethinking,ggplot2,ggthemes,bayesplot)
```

```{r load data}
data=read.csv("data/clean_data_short.csv")

#rename group_ID to just ID
colnames(data)[1]="ID"
data$ID = as.factor(data$ID)
```

# 1. Explore the data

Hypothesis 1: Group of friends make more mistakes than strangers
Hypothesis 2: Group of friends need more rounds to connect all words
```{r}
#create condition variable just for plotting purposes
data$condition=ifelse(data$friends==1,yes="Friends",no="Strangers")
data$condition=as.factor(data$condition)

#get descriptive statistics of all variables by condition
psych::describeBy(data,data$condition) #both mean and median are higher for friends

#plot the differences
(plot_mistakes=ggplot(data,aes(x=condition,y=mistakes,fill=condition))+
  geom_boxplot()+
  labs(title="Amount of mistakes")+
  scale_fill_fivethirtyeight())

(plot_rounds=ggplot(data,aes(x=condition,y=n_rounds,fill=condition))+
  geom_boxplot()+
  labs(title="Number of rounds")+
  scale_fill_fivethirtyeight())

ggsave("Figures/Aggregated/Mistakes_plot.jpg", plot_mistakes)
ggsave("Figures/Aggregated/N_rounds_plot.jpg", plot_rounds)

```

So the patterns seem to be in the data. Now we can test it with models.

# 2. Build simple models (1 predictor/interaction)
First we build the simplest models

Construct priors for intercept and beta (same for all models)

```{r}
priors = data.frame(alpha = rnorm(0,0.05,n=1e4),
                    beta = rnorm(0,0.2,n=1e4))

priors = reshape2::melt(priors)

(priors_plot=ggplot(priors,aes(x=value,color=variable))+
  geom_line(stat="density"))

ggsave("Figures/Aggregated/Priors_plot.jpg",priors_plot)
```


Condition predicted from mistakes
```{r}
m_mistakes = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a + bM*mistakes ,
        a ~ dnorm(0,0.05),
        bM ~ dnorm(0,0.2)
    ) ,
    data=data,
    iter = 1e4,warmup = 1000,chains = 2,cores=2)

plot(m_mistakes)
pairs(m_mistakes)

m_mistakes_random = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a[ID] + bM*mistakes ,
        a[ID] ~ dnorm(0,0.05),
        bM ~ dnorm(0,0.2)
    ) ,
    data=data,
    iter = 1e4,warmup = 1000,chains = 2,cores=2)

plot(m_mistakes_random)
pairs(m_mistakes_random)

#the models are basically the same + give us similar results
compare(m_mistakes,m_mistakes_random)

#look at the results
(mistakes_results = precis(m_mistakes_random,depth = 2))
mistakes_results = round(mistakes_results@output,3)
plot(mistakes_results)

write.csv(mistakes_results,"Results/Aggregated/mistakes_results.csv")

#make a plot of the increasing odds with increasing the mistakes

#generate predictions for sequence of mistakes
mistakes_vis=data.frame(mistakes=seq(0,30,by=1),condition=rep(0,31),ID=rep(1, 31))

l_mis=link(m_mistakes_random,data=mistakes_vis,1e4)
mistakes_vis$mean=apply(l_mis , 2 , mean )
mistakes_vis=cbind(mistakes_vis,as.data.frame(t(apply(l_mis , 2 , PI , prob=0.89 ))))

(odds_plot_mistakes=ggplot(mistakes_vis,aes(x=mistakes))+
  geom_line(aes(y=mean))+
  geom_ribbon(aes(ymin=`5%`,ymax=`94%`),alpha=0.3,fill="#0092ff")+
  labs(title="Increase in odds of being friends with increasing number of mistakes",x="Odds",y="Number of mistakes"))

ggsave("Figures/Aggregated/Plot_increasing_odds_mistakes.jpg",odds_plot_mistakes)
```

Condition predicted from n_rounds
```{r}
m_rounds = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a + bR*n_rounds ,
        a ~ dnorm(0,0.05),
        bR ~ dnorm(0,0.2)
    ) ,
    data=data,
    chains = 2,
    iter=1e4,
    cores = 2)

plot(m_rounds)
pairs(m_rounds)

m_rounds_random = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a[ID] + bR*n_rounds ,
        a[ID] ~ dnorm(0,0.05),
        bR ~ dnorm(0,0.2)
    ) ,
    data=data,
    chains = 2,
    iter=1e4,
    cores = 2)

plot(m_rounds_random)
pairs(m_rounds_random)
```


Now build a model that has both predictors of above models
```{r}
m_all = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a + bM*mistakes +bR*n_rounds ,
        a ~ dnorm(0,0.05),
        bR ~ dnorm(0,0.2),
        bM ~ dnorm(0,0.2)
    ) ,
    data=data,
    chains = 2,
    iter=1e4,
    cores = 2)

m_all_random = map2stan(
    alist(
        friends ~ dbinom( 1 , p ) ,
        logit(p) <- a[ID] + bM*mistakes +bR*n_rounds ,
        a[ID] ~ dnorm(0,0.05),
        bR ~ dnorm(0,0.2),
        bM ~ dnorm(0,0.2)
    ) ,
    data=data,
    chains = 2,
    iter=1e4,
    cores = 2)

compare(m_all,m_all_random)
```

Is it necessary to do plots for m_all?
```{r}
comparison=compare(m_all_random,m_all,m_mistakes,m_mistakes_random,m_rounds,m_rounds_random) #the m_all has the highest WAIC, effects seem to be the same too - no need for more plots
comparison=round(comparison@output,3)

write.csv(comparison,"Results/Aggregated/model_selection.csv")
```

Model quality check - with PPC plots (equivalent to confusion matrix)
```{r}
yrep_m=sim(m_mistakes_random,n=1e4)
yrep_r=sim(m_rounds,n=1e4)
yrep_a=sim(m_all_random,n=1e4)

#and ensemble
ens = ensemble(m_all_random,m_all,m_mistakes,m_mistakes_random,m_rounds,m_rounds_random,data=data)
yrep_ens=ens$sim

y=data$friends

success <- function(x) sum(x == 1)/length(x)

y_success=success(y)
success(yrep_m)-y_success
success(yrep_r)-y_success
success(yrep_a)-y_success
success(yrep_ens)-y_success

(PPC_mistakes=ppc_stat(y,yrep_m,stat="success",binwidth = 0.05)+
  labs(title="Proportion of group of friends predicted from mistakes",x="proportion of friends",y="n of models"))
(PPC_rounds=ppc_stat(y,yrep_r,stat="success",binwidth = 0.05)+
  labs(title="Proportion of group of friends predicted from rounds",x="proportion of friends",y="n of models"))
(PPC_all=ppc_stat(y,yrep_a,stat="success",binwidth = 0.05)+
  labs(title="Proportion of group of friends predicted from mistakes and rounds",x="proportion of friends",y="n of models"))
(PPC_ensemble=ppc_stat(y,yrep_ens,stat="success",binwidth = 0.05)+
  labs(title="Proportion of group of friends predicted ensemble of all models",x="proportion of friends",y="n of models"))

ggsave("Figures/Aggregated/PPC_mistakes.jpg",PPC_mistakes)
ggsave("Figures/Aggregated/PPC_rounds.jpg",PPC_rounds)
ggsave("Figures/Aggregated/PPC_short_model_all.jpg",PPC_all)
ggsave("Figures/Aggregated/PPC_short_ensemble.jpg",PPC_ensemble)
```

According to the PPC plot the full model seems to predict the data the best so let's look at its results and plot them. (report probably either just that or the 2 separate)
```{r}
(all_result = precis(m_all_random,depth = 2))
all_result=round(all_result@output,3)

plot(precis(m_all_random,depth = 2))

write.csv(all_result,"Results/Aggregated/short_model_all.csv")
```

Plot the effect of rounds - overlaps with zero so it will look quite bad again but it's in opposite direction after the mistakes are accounted for
```{r}
#make new data to predict where rounds change and mistakes stay constant at 0
all_vis_rounds=data.frame(n_rounds=seq(0,30,by=1),mistakes=rep(0,31),condition=rep(0,31),ID=rep(1,31))

all_l_rounds=link(m_all_random,data=all_vis_rounds,1e4)
all_vis_rounds$mean=apply(all_l_rounds , 2 , mean )
all_vis_rounds=cbind(all_vis_rounds,as.data.frame(t(apply(all_l_rounds , 2 , PI , prob=0.89 ))))

(odds_plot_rounds_all=ggplot(all_vis_rounds,aes(x=n_rounds))+
  geom_line(aes(y=mean))+
  geom_ribbon(aes(ymin=`5%`,ymax=`94%`),alpha=0.5,fill="#0092ff")+
  labs(title="Change of odds of being friends with increasing number of rounds",x="Number of rounds",y="Odds"))

ggsave("Figures/Aggregated/Odds_change_rounds_all.jpg",odds_plot_rounds_all)
```


Compare prior and posterior
```{r}
samples_mistakes = extract.samples(m_mistakes_random,n=1e4)
samples_all = extract.samples(m_all_random,n=1e4)

prior=rnorm(0,0.2,n=1e4)

PP_mistakes = data.frame(Prior=prior,Posterior=samples_mistakes$bM)
PP_rounds = data.frame(Prior=prior,Posterior=samples_all$bR)

PP_mistakes = reshape2::melt(PP_mistakes)
PP_rounds = reshape2::melt(PP_rounds)

(PP_mist_plot=ggplot(PP_mistakes,aes(x=value,color=variable))+
  geom_line(stat = "density")+
  labs(title="Prior and posterior of the effect of mistakes"))

(PP_rounds_plot=ggplot(PP_rounds,aes(x=value,color=variable))+
  geom_line(stat = "density")+
  labs(title="Prior and posterior of the effect of n_rounds"))

ggsave("Figures/Aggregated/PP_mistakes.jpg",PP_mist_plot)
ggsave("Figures/Aggregated/PP_rounds.jpg",PP_rounds_plot)

#what is the probability the mistakes effect is only positive (no overlap with 0)
post_mist = samples_mistakes$bM
sum(post_mist<0)/length(post_mist)

post_rounds = samples_all$bR
sum(post_rounds<0)/length(post_rounds)
```